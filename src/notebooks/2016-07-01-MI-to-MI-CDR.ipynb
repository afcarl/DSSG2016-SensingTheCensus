{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy\n",
    "from pandas.io.json import json_normalize\n",
    "from scipy.spatial.distance import cosine\n",
    "import csv\n",
    "# from pyspark import SparkContext\n",
    "# from pyspark import SparkConf\n",
    "# from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf #user defined function\n",
    "from pyspark.sql.functions import lit, col\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import HiveContext\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not needed for Spark on EC2, only for local setup\n",
    "# sc = SparkContext(\"local\", \"Region Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading the raw data\n",
    "# df = pd.read_csv('../../data/CDR/hash/sample.csv') \n",
    "# df.columns = ['index','time','source','dest','call']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time          source dest call                \n",
      "1383297600000 1      1    1.445982643495844E-4\n",
      "1383300000000 1      1    2.893335821627406...\n",
      "1383306000000 1      1    2.170344499879484...\n",
      "1383306600000 1      1    6.92190810703531E-5 \n",
      "1383308400000 1      1    7.22991321747922E-5 \n",
      "1383309000000 1      1    2.107372943154984E-4\n",
      "1383315000000 1      1    7.395236931786679E-5\n",
      "1383317400000 1      1    6.92190810703531E-5 \n",
      "1383331200000 1      1    6.92190810703531E-5 \n",
      "1383339600000 1      1    7.22991321747922E-5 \n",
      "1383342000000 1      1    7.551623674280319E-5\n",
      "1383342600000 1      1    6.92190810703531E-5 \n",
      "1383265800000 1      10   2.814243229598746E-5\n",
      "1383288000000 1      10   3.907339743793248E-5\n",
      "1383296400000 1      10   1.028247752913052E-4\n",
      "1383297000000 1      10   1.309672075872926...\n",
      "1383298800000 1      10   1.551390040413683E-4\n",
      "1383299400000 1      10   1.092125409370522...\n",
      "1383305400000 1      10   1.569513613199081...\n",
      "1383307800000 1      10   1.040236849748308...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading the raw data\n",
    "# df = pd.read_csv('../../data/CDR/hash/sample.csv') \n",
    "# df.columns = ['index','time','source','dest','call']\n",
    "# sqlCtx = SQLContext(sc)\n",
    "# cs_df = sqlCtx.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# loading the cell-proportion data\n",
    "prop_table = pd.read_csv('../../data/CDR/hash/cell_intersect.csv', header = None) \n",
    "prop_table.columns = ['cell', 'proportions']\n",
    "prop_table.index = prop_table.cell\n",
    "prop_table.sort_values(['cell'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_cells_per_region(table, region_id):\n",
    "    ids = table.iloc[region_id].proportions\n",
    "    ids = ast.literal_eval(table.get_value(region_id, \"proportions\"))\n",
    "    return ids.keys()\n",
    "\n",
    "def get_call_data(source, dest, cs_df, table):        \n",
    "    source_dict = get_cells_per_region(table, source)\n",
    "    dest_dict = get_cells_per_region(table, dest)\n",
    "    query = \"SELECT * from cs_df WHERE \"\n",
    "    \n",
    "    i = 1    \n",
    "    \n",
    "    for skey in source_dict:                  \n",
    "        query += \"source = \" + str(skey) \n",
    "        if len(source_dict) > i:\n",
    "            query += \" OR \"\n",
    "        i += 1\n",
    "    \n",
    "    subset = sqlCtx.sql(query)\n",
    "    subset.registerTempTable(\"subset\")\n",
    "    \n",
    "    i=1\n",
    "    query = \"SELECT * from subset WHERE \"\n",
    "            \n",
    "    for dkey in dest_dict:  \n",
    "        query += \"dest = \" + str(dkey)\n",
    "        if len(dest_dict) > i:\n",
    "            query += \" OR \"\n",
    "        i += 1\n",
    "        \n",
    "    subset2 = sqlCtx.sql(query)\n",
    "            \n",
    "    return subset2\n",
    "\n",
    "def calculate_actual_call(s_cell, d_cell, call, s_region, d_region):\n",
    "    \"\"\"\n",
    "        Create another column on the subset DataFrame that is proportional to the regions.\n",
    "    \"\"\"\n",
    "    source_prop = ast.literal_eval(prop_table.get_value(int(s_cell), \"proportions\"))\n",
    "    dest_prop = ast.literal_eval(prop_table.get_value(int(d_cell), \"proportions\"))\n",
    "\n",
    "    try:\n",
    "        final = source_prop[str(s_region)] * dest_prop[str(d_region)] * float(call)\n",
    "    except:\n",
    "        final = 0\n",
    "    \n",
    "    return float(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(1, 4)\n",
      "(1, 5)\n",
      "(1, 6)\n",
      "(1, 7)\n",
      "(1, 8)\n",
      "(1, 9)\n",
      "(1, 10)\n",
      "(1, 11)\n",
      "(1, 12)\n",
      "(1, 13)\n",
      "(1, 14)\n",
      "(1, 15)\n",
      "(1, 16)\n",
      "(1, 17)\n",
      "(1, 18)\n",
      "(1, 19)\n",
      "(1, 20)\n",
      "(1, 21)\n",
      "(1, 22)\n",
      "(1, 23)\n",
      "(1, 24)\n",
      "(1, 25)\n",
      "(1, 26)\n",
      "(1, 27)\n",
      "(1, 28)\n",
      "(1, 29)\n",
      "(1, 30)\n",
      "(1, 31)\n",
      "(1, 32)\n",
      "(1, 33)\n",
      "(1, 34)\n",
      "(1, 35)\n",
      "(1, 36)\n",
      "(1, 37)\n",
      "(1, 38)\n",
      "(1, 39)\n",
      "(1, 40)\n",
      "(1, 41)\n",
      "(1, 42)\n",
      "(1, 43)\n",
      "(1, 44)\n",
      "(1, 45)\n",
      "(1, 46)\n",
      "(1, 47)\n",
      "(1, 48)\n",
      "(1, 49)\n",
      "(1, 50)\n",
      "(1, 51)\n",
      "(1, 52)\n",
      "(1, 53)\n",
      "(1, 54)\n",
      "(1, 55)\n",
      "(1, 56)\n",
      "(1, 57)\n",
      "(1, 58)\n",
      "(1, 59)\n",
      "(1, 60)\n",
      "(1, 61)\n",
      "(1, 62)\n",
      "(1, 63)\n",
      "(1, 64)\n",
      "(1, 65)\n",
      "(1, 66)\n",
      "(1, 67)\n",
      "(1, 68)\n",
      "(1, 69)\n",
      "(1, 70)\n",
      "(1, 71)\n",
      "(1, 72)\n",
      "(1, 73)\n",
      "(1, 74)\n",
      "(1, 75)\n",
      "(1, 76)\n",
      "(1, 77)\n",
      "(1, 78)\n",
      "(1, 79)\n",
      "(1, 80)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sqlCtx = SQLContext(sc)\n",
    "    rdd = sc.textFile(\"hdfs://ip-10-46-133-118.us-west-2.compute.internal:9000/user/root/mi-to-mi/*\").map(lambda row:row.split('\\t'))\n",
    "    cs_df = sqlCtx.createDataFrame(rdd, ['time','source','dest','call'])\n",
    "    \n",
    "    cs_df.registerTempTable(\"cs_df\")\n",
    "    sqlCtx.cacheTable(\"cs_df\")\n",
    "\n",
    "    # loading the region-cell data\n",
    "    table = pd.read_csv('../../data/CDR/hash/intersect.csv', header = None) \n",
    "    table.columns = ['region', 'proportions']\n",
    "    table.index = table.region\n",
    "    table.sort_values(['region'], inplace=True)\n",
    "    \n",
    "    schema = StructType([\n",
    "                StructField(\"time\", IntegerType(), nullable=False),\n",
    "                StructField(\"adjusted_call\", FloatType(), nullable=False),\n",
    "                StructField(\"source_region\", FloatType(), nullable=False),\n",
    "                StructField(\"dest_region\", FloatType(), nullable=False)            \n",
    "        ])\n",
    "\n",
    "    region_network = sqlCtx.createDataFrame([], schema)\n",
    "    udf_calls = udf(calculate_actual_call, FloatType())\n",
    "\n",
    "    for s in range(1,2):\n",
    "        for d in range(1,81):\n",
    "            # get a subset of records for the source and dest\n",
    "            subdf = get_call_data(s, d, cs_df, table)        \n",
    "            subdf = subdf.withColumn(\"source_region\", lit(s))\n",
    "            subdf = subdf.withColumn(\"dest_region\", lit(d))\n",
    "            print (s, d)\n",
    "            # create a column with adjusted call values\n",
    "            try:\n",
    "                subdf = subdf.select(\"time\",\"source\", \"dest\", \"call\", \"source_region\", \"dest_region\", udf_calls(\"source\", \"dest\", \"call\", \"source_region\", \"dest_region\").alias(\"adjusted_call\"))\n",
    "                # subdf = subdf.withColumn(\"adjusted_call\", udf_calls(\"source\", \"dest\", \"call\", \"source_region\", \"dest_region\"))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # do aggregation for \n",
    "            subdf = subdf.groupBy(\"time\").agg({                \n",
    "                    \"source_region\": \"max\",\n",
    "                    \"dest_region\": \"max\",\n",
    "                    \"adjusted_call\": \"sum\"\n",
    "                })\n",
    "            region_network = region_network.unionAll(subdf)\n",
    "\n",
    "        region_network.toPandas().to_csv('../../data/CDR/generated/region-network_'+ str(s) +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
