{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy\n",
    "from pandas.io.json import json_normalize\n",
    "from scipy.spatial.distance import cosine\n",
    "import csv\n",
    "# from pyspark import SparkContext\n",
    "# from pyspark import SparkConf\n",
    "# from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf #user defined function\n",
    "from pyspark.sql.functions import lit, col\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import HiveContext\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not needed for Spark on EC2, only for local setup\n",
    "# sc = SparkContext(\"local\", \"Region Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading the raw data\n",
    "# df = pd.read_csv('../../data/CDR/hash/sample.csv') \n",
    "# df.columns = ['index','time','source','dest','call']\n",
    "sqlCtx = SQLContext(sc)\n",
    "df = sc.textFile(\"s3n://census-cdr/mi-to-mi/*\").map(lambda row:row.split(','))\n",
    "cs_df = sqlCtx.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs_df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# loading the region-cell data\n",
    "table = pd.read_csv('../../data/CDR/hash/intersect.csv', header = None) \n",
    "table.columns = ['region', 'proportions']\n",
    "table.index = table.region\n",
    "table.sort_values(['region'], inplace=True)\n",
    "\n",
    "# loading the cell-proportion data\n",
    "prop_table = pd.read_csv('../../data/CDR/hash/cell_intersect.csv', header = None) \n",
    "prop_table.columns = ['cell', 'proportions']\n",
    "prop_table.index = prop_table.cell\n",
    "prop_table.sort_values(['cell'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_cells_per_region(table, region_id):\n",
    "    ids = table.iloc[region_id].proportions\n",
    "    ids = ast.literal_eval(table.get_value(region_id, \"proportions\"))\n",
    "    return ids.keys()\n",
    "\n",
    "def get_call_data(source, dest):        \n",
    "    source_dict = get_cells_per_region(table, source)\n",
    "    dest_dict = get_cells_per_region(table, dest)\n",
    "    query = \"SELECT * from cs_df WHERE \"\n",
    "    \n",
    "    cs_df.registerTempTable(\"cs_df\")\n",
    "    i = 1    \n",
    "    \n",
    "    for skey in source_dict:                  \n",
    "        query += \"source = \" + str(skey) \n",
    "        if len(source_dict) > i:\n",
    "            query += \" OR \"\n",
    "        i += 1\n",
    "    \n",
    "    subset = sqlCtx.sql(query)\n",
    "    subset.registerTempTable(\"subset\")\n",
    "    \n",
    "    i=1\n",
    "    query = \"SELECT * from subset WHERE \"\n",
    "            \n",
    "    for dkey in dest_dict:  \n",
    "        query += \"dest = \" + str(dkey)\n",
    "        if len(dest_dict) > i:\n",
    "            query += \" OR \"\n",
    "        i += 1\n",
    "        \n",
    "    subset2 = sqlCtx.sql(query)\n",
    "            \n",
    "    return subset2\n",
    "\n",
    "def calculate_actual_call(s_cell, d_cell, call, s_region, d_region):\n",
    "    \"\"\"\n",
    "        Create another column on the subset DataFrame that is proportional to the regions.\n",
    "    \"\"\"\n",
    "    source_prop = ast.literal_eval(prop_table.get_value(s_cell, \"proportions\"))\n",
    "    dest_prop = ast.literal_eval(prop_table.get_value(d_cell, \"proportions\"))\n",
    "\n",
    "    try:\n",
    "        final = source_prop[str(s_region)] * dest_prop[str(d_region)] * call\n",
    "    except:\n",
    "        final = 0\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "schema = StructType([\n",
    "            StructField(\"time\", IntegerType(), nullable=False),\n",
    "            StructField(\"adjusted_call\", FloatType(), nullable=False),\n",
    "            StructField(\"source_region\", IntegerType(), nullable=False),\n",
    "            StructField(\"dest_region\", IntegerType(), nullable=False)            \n",
    "    ])\n",
    "\n",
    "region_network = sqlCtx.createDataFrame([], schema)\n",
    "udf_calls = udf(calculate_actual_call, FloatType())\n",
    "\n",
    "for s in range(53,81):\n",
    "    for d in range(53,55):\n",
    "        # get a subset of records for the source and dest\n",
    "        subdf = get_call_data(s, d)        \n",
    "        subdf = subdf.withColumn(\"source_region\", lit(s))\n",
    "        subdf = subdf.withColumn(\"dest_region\", lit(d))\n",
    "        print (s, d)\n",
    "        # create a column with adjusted call values\n",
    "        try:\n",
    "            subdf = subdf.select(\"time\",\"source\", \"dest\", \"call\", \"source_region\", \"dest_region\", udf_calls(\"source\", \"dest\", \"call\", \"source_region\", \"dest_region\").alias(\"adjusted_call\"))\n",
    "            # subdf = subdf.withColumn(\"adjusted_call\", udf_calls(\"source\", \"dest\", \"call\", \"source_region\", \"dest_region\"))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # do aggregation for \n",
    "        subdf = subdf.groupBy(\"time\").agg({                \n",
    "                \"source_region\": \"max\",\n",
    "                \"dest_region\": \"max\",\n",
    "                \"adjusted_call\": \"sum\"\n",
    "            })\n",
    "        region_network = region_network.unionAll(subdf)\n",
    "    break\n",
    "        \n",
    "region_network.show()\n",
    "region_network.toPandas().to_csv('../../data/CDR/generated/region-network.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
